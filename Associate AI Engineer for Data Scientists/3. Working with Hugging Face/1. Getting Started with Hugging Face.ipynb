{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-28T20:13:53.411584Z",
     "start_time": "2025-03-28T20:13:13.257780Z"
    }
   },
   "source": [
    "from mpmath import limit\n",
    "!pip install transformers datasets"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/aa/22/733a6fc4a6445d835242f64c490fdd30f4a08d58f2b788613de3f9170692/transformers-4.50.3-py3-none-any.whl.metadata\n",
      "  Downloading transformers-4.50.3-py3-none-any.whl.metadata (39 kB)\n",
      "Collecting datasets\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/b4/83/50abe521eb75744a01efe2ebe836a4b61f4df37941a776f650f291aabdf9/datasets-3.5.0-py3-none-any.whl.metadata\n",
      "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting filelock (from transformers)\n",
      "  Obtaining dependency information for filelock from https://files.pythonhosted.org/packages/4d/36/2a115987e2d8c300a974597416d9de88f2444426de9571f4b59b2cca3acc/filelock-3.18.0-py3-none-any.whl.metadata\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting huggingface-hub<1.0,>=0.26.0 (from transformers)\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.26.0 from https://files.pythonhosted.org/packages/40/0c/37d380846a2e5c9a3c6a73d26ffbcfdcad5fc3eacf42fdf7cff56f2af634/huggingface_hub-0.29.3-py3-none-any.whl.metadata\n",
      "  Downloading huggingface_hub-0.29.3-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from transformers) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Collecting regex!=2019.12.17 (from transformers)\n",
      "  Obtaining dependency information for regex!=2019.12.17 from https://files.pythonhosted.org/packages/38/ec/ad2d7de49a600cdb8dd78434a1aeffe28b9d6fc42eb36afab4a27ad23384/regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl.metadata (41 kB)\n",
      "     ---------------------------------------- 0.0/41.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 41.5/41.5 kB 2.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Collecting tokenizers<0.22,>=0.21 (from transformers)\n",
      "  Obtaining dependency information for tokenizers<0.22,>=0.21 from https://files.pythonhosted.org/packages/e6/b6/072a8e053ae600dcc2ac0da81a23548e3b523301a442a6ca900e92ac35be/tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata\n",
      "  Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting safetensors>=0.4.3 (from transformers)\n",
      "  Obtaining dependency information for safetensors>=0.4.3 from https://files.pythonhosted.org/packages/69/e2/b011c38e5394c4c18fb5500778a55ec43ad6106126e74723ffaee246f56e/safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata\n",
      "  Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting tqdm>=4.27 (from transformers)\n",
      "  Obtaining dependency information for tqdm>=4.27 from https://files.pythonhosted.org/packages/d0/30/dc54f88dd4a2b5dc8a0279bdd7270e735851848b762aeb1c1184ed1f6b14/tqdm-4.67.1-py3-none-any.whl.metadata\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting pyarrow>=15.0.0 (from datasets)\n",
      "  Obtaining dependency information for pyarrow>=15.0.0 from https://files.pythonhosted.org/packages/16/33/2a67c0f783251106aeeee516f4806161e7b481f7d744d0d643d2f30230a5/pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Obtaining dependency information for dill<0.3.9,>=0.3.0 from https://files.pythonhosted.org/packages/c9/7a/cef76fd8438a42f96db64ddaa85280485a9c395e7df3db8158cfec1eee34/dill-0.3.8-py3-none-any.whl.metadata\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pandas in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Collecting xxhash (from datasets)\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/d9/6b/1c443fe6cfeb4ad1dcf231cdec96eb94fb43d6498b4469ed8b51f8b59a37/xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets)\n",
      "  Obtaining dependency information for multiprocess<0.70.17 from https://files.pythonhosted.org/packages/0a/7d/a988f258104dcd2ccf1ed40fdc97e26c4ac351eeaf81d76e266c52d84e2f/multiprocess-0.70.16-py312-none-any.whl.metadata\n",
      "  Using cached multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec[http]<=2024.12.0,>=2023.1.0 (from datasets)\n",
      "  Obtaining dependency information for fsspec[http]<=2024.12.0,>=2023.1.0 from https://files.pythonhosted.org/packages/de/86/5486b0188d08aa643e127774a99bac51ffa6cf343e3deb0583956dca5b22/fsspec-2024.12.0-py3-none-any.whl.metadata\n",
      "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting aiohttp (from datasets)\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/3f/5f/1737cf6fcf0524693a4aeff8746530b65422236761e7bfdd79c6d2ce2e1c/aiohttp-3.11.14-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading aiohttp-3.11.14-cp312-cp312-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for aiohappyeyeballs>=2.3.0 from https://files.pythonhosted.org/packages/0f/15/5bf3b99495fb160b63f95972b81750f18f7f4e02ad051373b669d17d44f2/aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for aiosignal>=1.1.2 from https://files.pythonhosted.org/packages/ec/6a/bc7e17a3e87a2985d3e8f4da4cd0f481060eb78fb08596c42be62c90a4d9/aiosignal-1.3.2-py2.py3-none-any.whl.metadata\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/b1/56/4e45136ffc6bdbfa68c29ca56ef53783ef4c2fd395f7cbf99a2624aa9aaa/frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for multidict<7.0,>=4.5 from https://files.pythonhosted.org/packages/3c/f5/f147000fe1f4078160157b15b0790fff0513646b0f9b7404bf34007a9b44/multidict-6.2.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading multidict-6.2.0-cp312-cp312-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for propcache>=0.2.0 from https://files.pythonhosted.org/packages/24/bb/3b1b01da5dd04c77a204c84e538ff11f624e31431cfde7201d9110b092b1/propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp->datasets)\n",
      "  Obtaining dependency information for yarl<2.0,>=1.17.0 from https://files.pythonhosted.org/packages/34/45/0e055320daaabfc169b21ff6174567b2c910c45617b0d79c68d7ab349b02/yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl.metadata (71 kB)\n",
      "     ---------------------------------------- 0.0/71.4 kB ? eta -:--:--\n",
      "     ---------------------------------------- 71.4/71.4 kB 2.0 MB/s eta 0:00:00\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Downloading transformers-4.50.3-py3-none-any.whl (10.2 MB)\n",
      "   ---------------------------------------- 0.0/10.2 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.7/10.2 MB 14.4 MB/s eta 0:00:01\n",
      "   ------- -------------------------------- 1.9/10.2 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 3.4/10.2 MB 23.9 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 5.0/10.2 MB 26.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 6.7/10.2 MB 28.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 8.3/10.2 MB 29.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 9.5/10.2 MB 29.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  10.2/10.2 MB 27.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 10.2/10.2 MB 25.0 MB/s eta 0:00:00\n",
      "Downloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
      "   ---------------------------------------- 0.0/491.2 kB ? eta -:--:--\n",
      "   --------------------------------------- 491.2/491.2 kB 32.1 MB/s eta 0:00:00\n",
      "Using cached dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "Downloading aiohttp-3.11.14-cp312-cp312-win_amd64.whl (438 kB)\n",
      "   ---------------------------------------- 0.0/438.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 438.5/438.5 kB 26.8 MB/s eta 0:00:00\n",
      "Downloading huggingface_hub-0.29.3-py3-none-any.whl (468 kB)\n",
      "   ---------------------------------------- 0.0/469.0 kB ? eta -:--:--\n",
      "   --------------------------------------- 469.0/469.0 kB 28.7 MB/s eta 0:00:00\n",
      "Using cached multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading pyarrow-19.0.1-cp312-cp312-win_amd64.whl (25.3 MB)\n",
      "   ---------------------------------------- 0.0/25.3 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.4/25.3 MB 45.6 MB/s eta 0:00:01\n",
      "   --- ------------------------------------ 2.5/25.3 MB 31.9 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 3.3/25.3 MB 26.7 MB/s eta 0:00:01\n",
      "   ----- ---------------------------------- 3.4/25.3 MB 18.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 4.9/25.3 MB 22.3 MB/s eta 0:00:01\n",
      "   -------- ------------------------------- 5.5/25.3 MB 19.6 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.0/25.3 MB 18.4 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 6.2/25.3 MB 17.2 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.4/25.3 MB 15.8 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 6.9/25.3 MB 15.3 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 7.3/25.3 MB 14.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 7.7/25.3 MB 14.1 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 8.4/25.3 MB 13.8 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 9.2/25.3 MB 14.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 10.4/25.3 MB 14.6 MB/s eta 0:00:02\n",
      "   ------------------ --------------------- 12.0/25.3 MB 14.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.7/25.3 MB 17.3 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 15.6/25.3 MB 17.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 17.3/25.3 MB 25.2 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 19.1/25.3 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.8/25.3 MB 36.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 22.5/25.3 MB 36.4 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.7/25.3 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.7/25.3 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  25.2/25.3 MB 31.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 25.3/25.3 MB 25.1 MB/s eta 0:00:00\n",
      "Downloading regex-2024.11.6-cp312-cp312-win_amd64.whl (273 kB)\n",
      "   ---------------------------------------- 0.0/273.6 kB ? eta -:--:--\n",
      "   --------------------------------------- 273.6/273.6 kB 16.5 MB/s eta 0:00:00\n",
      "Downloading safetensors-0.5.3-cp38-abi3-win_amd64.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 308.9/308.9 kB 18.7 MB/s eta 0:00:00\n",
      "Downloading tokenizers-0.21.1-cp39-abi3-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ------------------------- -------------- 1.5/2.4 MB 47.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 38.5 MB/s eta 0:00:00\n",
      "Using cached tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Using cached xxhash-3.5.0-cp312-cp312-win_amd64.whl (30 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading frozenlist-1.5.0-cp312-cp312-win_amd64.whl (51 kB)\n",
      "   ---------------------------------------- 0.0/51.3 kB ? eta -:--:--\n",
      "   ---------------------------------------- 51.3/51.3 kB ? eta 0:00:00\n",
      "Downloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
      "   ---------------------------------------- 0.0/183.9 kB ? eta -:--:--\n",
      "   --------------------------------------- 183.9/183.9 kB 11.6 MB/s eta 0:00:00\n",
      "Downloading multidict-6.2.0-cp312-cp312-win_amd64.whl (28 kB)\n",
      "Downloading propcache-0.3.1-cp312-cp312-win_amd64.whl (44 kB)\n",
      "   ---------------------------------------- 0.0/44.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 44.8/44.8 kB ? eta 0:00:00\n",
      "Downloading yarl-1.18.3-cp312-cp312-win_amd64.whl (90 kB)\n",
      "   ---------------------------------------- 0.0/90.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 90.4/90.4 kB ? eta 0:00:00\n",
      "Installing collected packages: xxhash, tqdm, safetensors, regex, pyarrow, propcache, multidict, fsspec, frozenlist, filelock, dill, aiohappyeyeballs, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 datasets-3.5.0 dill-0.3.8 filelock-3.18.0 frozenlist-1.5.0 fsspec-2024.12.0 huggingface-hub-0.29.3 multidict-6.2.0 multiprocess-0.70.16 propcache-0.3.1 pyarrow-19.0.1 regex-2024.11.6 safetensors-0.5.3 tokenizers-0.21.1 tqdm-4.67.1 transformers-4.50.3 xxhash-3.5.0 yarl-1.18.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:15:50.112558Z",
     "start_time": "2025-03-28T20:14:22.964323Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install torch torchvision torchaudio",
   "id": "62628f2cf830ee79",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Obtaining dependency information for torch from https://files.pythonhosted.org/packages/18/cf/ae99bd066571656185be0d88ee70abc58467b76f2f7c8bfeb48735a71fe6/torch-2.6.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torch-2.6.0-cp312-cp312-win_amd64.whl.metadata (28 kB)\n",
      "Collecting torchvision\n",
      "  Obtaining dependency information for torchvision from https://files.pythonhosted.org/packages/4c/6a/c7752603060d076dfed95135b78b047dc71792630cbcb022e3693d6f32ef/torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torchvision-0.21.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Collecting torchaudio\n",
      "  Obtaining dependency information for torchaudio from https://files.pythonhosted.org/packages/80/95/29e917905328337c7b104ce81f3bb5e2ad8dc70af2edf1d43f67eb621513/torchaudio-2.6.0-cp312-cp312-win_amd64.whl.metadata\n",
      "  Downloading torchaudio-2.6.0-cp312-cp312-win_amd64.whl.metadata (6.7 kB)\n",
      "Requirement already satisfied: filelock in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch) (4.12.2)\n",
      "Collecting networkx (from torch)\n",
      "  Obtaining dependency information for networkx from https://files.pythonhosted.org/packages/b9/54/dd730b32ea14ea797530a4479b2ed46a6fb250f682a9cfb997e968bf0261/networkx-3.4.2-py3-none-any.whl.metadata\n",
      "  Using cached networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: jinja2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch) (76.0.0)\n",
      "Collecting sympy==1.13.1 (from torch)\n",
      "  Obtaining dependency information for sympy==1.13.1 from https://files.pythonhosted.org/packages/b2/fe/81695a1aa331a842b582453b605175f419fe8540355886031328089d840a/sympy-1.13.1-py3-none-any.whl.metadata\n",
      "  Using cached sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch)\n",
      "  Obtaining dependency information for mpmath<1.4,>=1.1.0 from https://files.pythonhosted.org/packages/43/e3/7d92a15f894aa0c9c4b49b8ee9ac9850d6e63b03c9c32c0367a13ae62209/mpmath-1.3.0-py3-none-any.whl.metadata\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Requirement already satisfied: numpy in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torchvision) (2.2.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torchvision) (11.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Downloading torch-2.6.0-cp312-cp312-win_amd64.whl (204.1 MB)\n",
      "   ---------------------------------------- 0.0/204.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/204.1 MB 1.7 MB/s eta 0:02:04\n",
      "   ---------------------------------------- 0.9/204.1 MB 10.9 MB/s eta 0:00:19\n",
      "   ---------------------------------------- 2.5/204.1 MB 19.7 MB/s eta 0:00:11\n",
      "    --------------------------------------- 3.4/204.1 MB 21.5 MB/s eta 0:00:10\n",
      "    --------------------------------------- 4.3/204.1 MB 21.3 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 5.6/204.1 MB 21.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 5.9/204.1 MB 21.0 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 8.3/204.1 MB 23.2 MB/s eta 0:00:09\n",
      "   - -------------------------------------- 10.1/204.1 MB 24.8 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 11.6/204.1 MB 28.5 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 12.2/204.1 MB 26.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 12.9/204.1 MB 24.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 13.7/204.1 MB 26.2 MB/s eta 0:00:08\n",
      "   -- ------------------------------------- 15.2/204.1 MB 25.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 16.1/204.1 MB 25.1 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 17.4/204.1 MB 25.2 MB/s eta 0:00:08\n",
      "   --- ------------------------------------ 18.9/204.1 MB 24.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 20.5/204.1 MB 25.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 22.0/204.1 MB 24.2 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 23.5/204.1 MB 27.3 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 24.9/204.1 MB 29.7 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 26.4/204.1 MB 31.2 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 28.3/204.1 MB 34.4 MB/s eta 0:00:06\n",
      "   ----- ---------------------------------- 30.1/204.1 MB 32.8 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 31.5/204.1 MB 34.4 MB/s eta 0:00:06\n",
      "   ------ --------------------------------- 33.3/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 35.0/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 36.8/204.1 MB 40.9 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 38.5/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ------- -------------------------------- 40.2/204.1 MB 36.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 41.9/204.1 MB 36.3 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 43.6/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 45.4/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 47.0/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 48.8/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   --------- ------------------------------ 50.5/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 52.2/204.1 MB 36.4 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 53.8/204.1 MB 36.3 MB/s eta 0:00:05\n",
      "   ---------- ----------------------------- 55.6/204.1 MB 34.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 56.9/204.1 MB 34.6 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 58.3/204.1 MB 34.4 MB/s eta 0:00:05\n",
      "   ----------- ---------------------------- 59.8/204.1 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 61.4/204.1 MB 32.8 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 61.7/204.1 MB 31.2 MB/s eta 0:00:05\n",
      "   ------------ --------------------------- 62.6/204.1 MB 27.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 64.4/204.1 MB 27.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 66.0/204.1 MB 27.3 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 67.2/204.1 MB 26.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 68.3/204.1 MB 27.3 MB/s eta 0:00:05\n",
      "   ------------- -------------------------- 69.8/204.1 MB 26.2 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 71.1/204.1 MB 25.1 MB/s eta 0:00:06\n",
      "   -------------- ------------------------- 72.4/204.1 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 74.2/204.1 MB 31.2 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 76.1/204.1 MB 31.2 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 77.9/204.1 MB 34.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 79.6/204.1 MB 36.4 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 80.7/204.1 MB 36.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 80.7/204.1 MB 36.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 81.1/204.1 MB 27.3 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 82.1/204.1 MB 26.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 83.8/204.1 MB 26.2 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 85.6/204.1 MB 25.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 87.0/204.1 MB 25.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 88.7/204.1 MB 25.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 90.6/204.1 MB 25.2 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 92.1/204.1 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 93.5/204.1 MB 36.4 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 95.1/204.1 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 97.0/204.1 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 98.8/204.1 MB 36.3 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 100.5/204.1 MB 34.4 MB/s eta 0:00:04\n",
      "   ------------------- ------------------- 102.3/204.1 MB 34.6 MB/s eta 0:00:03\n",
      "   ------------------- ------------------- 103.9/204.1 MB 36.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 105.2/204.1 MB 34.4 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 106.1/204.1 MB 32.8 MB/s eta 0:00:03\n",
      "   -------------------- ------------------ 107.1/204.1 MB 31.2 MB/s eta 0:00:04\n",
      "   -------------------- ------------------ 108.6/204.1 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 110.1/204.1 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 112.0/204.1 MB 29.7 MB/s eta 0:00:04\n",
      "   --------------------- ----------------- 113.8/204.1 MB 29.8 MB/s eta 0:00:04\n",
      "   ---------------------- ---------------- 115.5/204.1 MB 31.2 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 117.2/204.1 MB 36.4 MB/s eta 0:00:03\n",
      "   ---------------------- ---------------- 118.9/204.1 MB 36.3 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 120.6/204.1 MB 36.3 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 122.3/204.1 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 124.1/204.1 MB 38.5 MB/s eta 0:00:03\n",
      "   ----------------------- --------------- 125.1/204.1 MB 34.4 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 126.0/204.1 MB 32.8 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 127.2/204.1 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 128.3/204.1 MB 29.7 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 129.5/204.1 MB 27.3 MB/s eta 0:00:03\n",
      "   ------------------------ -------------- 130.7/204.1 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 132.2/204.1 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 133.9/204.1 MB 26.2 MB/s eta 0:00:03\n",
      "   ------------------------- ------------- 135.5/204.1 MB 28.4 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 137.3/204.1 MB 29.7 MB/s eta 0:00:03\n",
      "   -------------------------- ------------ 139.1/204.1 MB 32.8 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 140.9/204.1 MB 36.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 142.7/204.1 MB 36.3 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 144.5/204.1 MB 36.3 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 146.3/204.1 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 147.9/204.1 MB 36.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 148.9/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 150.5/204.1 MB 32.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 152.3/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 154.2/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 155.9/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 157.6/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 159.3/204.1 MB 36.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 160.0/204.1 MB 34.4 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 161.1/204.1 MB 32.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 162.8/204.1 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 164.5/204.1 MB 31.2 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 166.2/204.1 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 168.0/204.1 MB 31.2 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 169.8/204.1 MB 31.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------ 171.5/204.1 MB 38.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 173.3/204.1 MB 36.4 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 175.1/204.1 MB 38.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 176.8/204.1 MB 36.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ----- 178.0/204.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 179.6/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 180.6/204.1 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 182.1/204.1 MB 32.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 183.4/204.1 MB 29.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 184.9/204.1 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 186.2/204.1 MB 28.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 187.6/204.1 MB 29.7 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 189.1/204.1 MB 28.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 190.8/204.1 MB 29.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 192.5/204.1 MB 32.7 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 194.2/204.1 MB 32.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 195.7/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 196.8/204.1 MB 31.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 198.5/204.1 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  200.2/204.1 MB 32.7 MB/s eta 0:00:01\n",
      "   --------------------------------------  202.1/204.1 MB 34.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  203.8/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  204.1/204.1 MB 34.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 204.1/204.1 MB 10.7 MB/s eta 0:00:00\n",
      "Using cached sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
      "Downloading torchvision-0.21.0-cp312-cp312-win_amd64.whl (1.6 MB)\n",
      "   ---------------------------------------- 0.0/1.6 MB ? eta -:--:--\n",
      "   ----------------------------------- ---- 1.4/1.6 MB 44.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.6/1.6 MB 24.6 MB/s eta 0:00:00\n",
      "Downloading torchaudio-2.6.0-cp312-cp312-win_amd64.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------------- ---------------- 1.4/2.4 MB 29.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.4/2.4 MB 25.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 25.9 MB/s eta 0:00:00\n",
      "Using cached networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: mpmath, sympy, networkx, torch, torchvision, torchaudio\n",
      "Successfully installed mpmath-1.3.0 networkx-3.4.2 sympy-1.13.1 torch-2.6.0 torchaudio-2.6.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "encoder / decoder / self-attention mechanism",
   "id": "649abb8fb04d7912"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:25:14.495118Z",
     "start_time": "2025-03-28T20:25:11.974424Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install huggingface_hub",
   "id": "697667d9b701b84",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (0.29.3)\n",
      "Requirement already satisfied: filelock in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (2024.12.0)\n",
      "Requirement already satisfied: packaging>=20.9 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: requests in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface_hub) (4.12.2)\n",
      "Requirement already satisfied: colorama in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface_hub) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface_hub) (2025.1.31)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from huggingface_hub import HfApi\n",
    "api = HfApi()\n",
    "for model in api.list_models(): # list all the models\n",
    "    print(model)"
   ],
   "id": "59167cb5f4631c0a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:35:33.866041Z",
     "start_time": "2025-03-28T20:35:33.702977Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# search for specific task\n",
    "models = api.list_models(\n",
    "    filter=\"text-classification\",\n",
    "    sort=\"downloads\",\n",
    "    direction=-1, # 1 ascending, -1 descending\n",
    "    limit=5\n",
    ")\n",
    "for model in models:\n",
    "    print(model)"
   ],
   "id": "df941375fff856f2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelInfo(id='cross-encoder/ms-marco-MiniLM-L6-v2', author=None, sha=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 5, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=10360164, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=78, library_name='sentence-transformers', tags=['sentence-transformers', 'pytorch', 'jax', 'safetensors', 'bert', 'text-classification', 'transformers', 'text-ranking', 'en', 'dataset:sentence-transformers/msmarco', 'base_model:cross-encoder/ms-marco-MiniLM-L12-v2', 'base_model:finetune:cross-encoder/ms-marco-MiniLM-L12-v2', 'license:apache-2.0', 'region:us'], pipeline_tag='text-ranking', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None, security_repo_status=None)\n",
      "ModelInfo(id='distilbert/distilbert-base-uncased-finetuned-sst-2-english', author=None, sha=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=7071293, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=720, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'rust', 'onnx', 'safetensors', 'distilbert', 'text-classification', 'en', 'dataset:sst2', 'dataset:glue', 'arxiv:1910.01108', 'doi:10.57967/hf/0181', 'license:apache-2.0', 'model-index', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='text-classification', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None, security_repo_status=None)\n",
      "ModelInfo(id='papluca/xlm-roberta-base-language-detection', author=None, sha=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 5, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=4111332, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=326, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'safetensors', 'xlm-roberta', 'text-classification', 'generated_from_trainer', 'multilingual', 'ar', 'bg', 'de', 'el', 'en', 'es', 'fr', 'hi', 'it', 'ja', 'nl', 'pl', 'pt', 'ru', 'sw', 'th', 'tr', 'ur', 'vi', 'zh', 'dataset:papluca/language-identification', 'arxiv:1911.02116', 'base_model:FacebookAI/xlm-roberta-base', 'base_model:finetune:FacebookAI/xlm-roberta-base', 'doi:10.57967/hf/2064', 'license:mit', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='text-classification', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None, security_repo_status=None)\n",
      "ModelInfo(id='MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli', author=None, sha=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=3279710, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=202, library_name='transformers', tags=['transformers', 'pytorch', 'safetensors', 'deberta-v2', 'text-classification', 'zero-shot-classification', 'en', 'dataset:multi_nli', 'dataset:facebook/anli', 'dataset:fever', 'arxiv:2006.03654', 'license:mit', 'model-index', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='zero-shot-classification', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None, security_repo_status=None)\n",
      "ModelInfo(id='ProsusAI/finbert', author=None, sha=None, created_at=datetime.datetime(2022, 3, 2, 23, 29, 4, tzinfo=datetime.timezone.utc), last_modified=None, private=False, disabled=None, downloads=2991102, downloads_all_time=None, gated=None, gguf=None, inference=None, inference_provider_mapping=None, likes=835, library_name='transformers', tags=['transformers', 'pytorch', 'tf', 'jax', 'bert', 'text-classification', 'financial-sentiment-analysis', 'sentiment-analysis', 'en', 'arxiv:1908.10063', 'autotrain_compatible', 'endpoints_compatible', 'region:us'], pipeline_tag='text-classification', mask_token=None, card_data=None, widget_data=None, model_index=None, config=None, transformers_info=None, trending_score=None, siblings=None, spaces=None, safetensors=None, security_repo_status=None)\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-28T20:44:30.429205Z",
     "start_time": "2025-03-28T20:44:23.607297Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install accelerate",
   "id": "ecfb4875fcc4f1dd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting accelerate\n",
      "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/70/83/167d4b638bb758a966828eb8d23c5e7047825edfdf768ff5f4fb01440063/accelerate-1.5.2-py3-none-any.whl.metadata\n",
      "  Downloading accelerate-1.5.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (2.2.3)\n",
      "Requirement already satisfied: packaging>=20.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (2.6.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (0.29.3)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2024.12.0)\n",
      "Requirement already satisfied: requests in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n",
      "Requirement already satisfied: networkx in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: setuptools in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from torch>=2.0.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: colorama in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.21.0->accelerate) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "Downloading accelerate-1.5.2-py3-none-any.whl (345 kB)\n",
      "   ---------------------------------------- 0.0/345.1 kB ? eta -:--:--\n",
      "   ---- ---------------------------------- 41.0/345.1 kB 991.0 kB/s eta 0:00:01\n",
      "   ---------------------------------------- 345.1/345.1 kB 4.3 MB/s eta 0:00:00\n",
      "Installing collected packages: accelerate\n",
      "Successfully installed accelerate-1.5.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:23:23.365438Z",
     "start_time": "2025-03-29T09:22:24.107280Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# save a model locally\n",
    "from transformers import AutoModel\n",
    "\n",
    "modelId = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "\n",
    "model = AutoModel.from_pretrained(modelId, trust_remote_code=True)\n",
    "model.save_pretrained(save_directory=f\"models/{modelId}\")"
   ],
   "id": "f0c8d0d9a7e15973",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\GitHub\\Datacamp-AI-Engineer-for-Data-Scientists-Associate-Certification\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "D:\\GitHub\\Datacamp-AI-Engineer-for-Data-Scientists-Associate-Certification\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:142: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Murti\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:26:05.886304Z",
     "start_time": "2025-03-29T09:26:02.623712Z"
    }
   },
   "cell_type": "code",
   "source": "!pip install datasets",
   "id": "fefeb624e9f02cb7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: datasets in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: filelock in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (3.18.0)\n",
      "Requirement already satisfied: numpy>=1.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (4.67.1)\n",
      "Requirement already satisfied: xxhash in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: huggingface-hub>=0.24.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (0.29.3)\n",
      "Requirement already satisfied: packaging in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from datasets) (6.0.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from huggingface-hub>=0.24.0->datasets) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from requests>=2.32.2->datasets) (2025.1.31)\n",
      "Requirement already satisfied: colorama in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from tqdm>=4.66.3->datasets) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in d:\\github\\datacamp-ai-engineer-for-data-scientists-associate-certification\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:42:41.596822Z",
     "start_time": "2025-03-29T09:42:35.451846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset_builder\n",
    "data_builder = load_dataset_builder(\"imdb\")\n",
    "data_builder.info"
   ],
   "id": "3740dccc71c7afa2",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetInfo(description='', citation='', homepage='', license='', features={'text': Value(dtype='string', id=None), 'label': ClassLabel(names=['neg', 'pos'], id=None)}, post_processed=None, supervised_keys=None, builder_name='parquet', dataset_name='imdb', config_name='plain_text', version=0.0.0, splits={'train': SplitInfo(name='train', num_bytes=33432823, num_examples=25000, shard_lengths=None, dataset_name=None), 'test': SplitInfo(name='test', num_bytes=32650685, num_examples=25000, shard_lengths=None, dataset_name=None), 'unsupervised': SplitInfo(name='unsupervised', num_bytes=67106794, num_examples=50000, shard_lengths=None, dataset_name=None)}, download_checksums=None, download_size=83446840, post_processing_size=None, dataset_size=133190302, size_in_bytes=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:44:17.874475Z",
     "start_time": "2025-03-29T09:44:06.767818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"imdb\")\n",
    "data"
   ],
   "id": "6bbfcb562010a601",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 100%|| 25000/25000 [00:01<00:00, 24575.12 examples/s]\n",
      "Generating test split: 100%|| 25000/25000 [00:00<00:00, 399481.87 examples/s]\n",
      "Generating unsupervised split: 100%|| 50000/50000 [00:00<00:00, 397489.01 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 25000\n",
       "    })\n",
       "    unsupervised: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 50000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:45:26.337781Z",
     "start_time": "2025-03-29T09:45:20.530452Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data = load_dataset(\"imdb\", split=\"train\")\n",
    "data"
   ],
   "id": "e1bbc36c21f83a20",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 25000\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:47:47.001044Z",
     "start_time": "2025-03-29T09:47:46.988701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "filtered = data.filter(lambda row: row['label']==0)\n",
    "filtered"
   ],
   "id": "86061bee91b7264f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 12500\n",
       "})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:49:07.356510Z",
     "start_time": "2025-03-29T09:49:07.347575Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# slicing ... example selecting row 0 and 1\n",
    "sliced = filtered.select(range(2))\n",
    "sliced"
   ],
   "id": "50f45fb02ec47473",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'label'],\n",
       "    num_rows: 2\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T09:50:02.089712Z",
     "start_time": "2025-03-29T09:50:02.079984Z"
    }
   },
   "cell_type": "code",
   "source": "sliced[0][\"text\"] # getting the text of the first row",
   "id": "6c6a8704501f2add",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I rented I AM CURIOUS-YELLOW from my video store because of all the controversy that surrounded it when it was first released in 1967. I also heard that at first it was seized by U.S. customs if it ever tried to enter this country, therefore being a fan of films considered \"controversial\" I really had to see this for myself.<br /><br />The plot is centered around a young Swedish drama student named Lena who wants to learn everything she can about life. In particular she wants to focus her attentions to making some sort of documentary on what the average Swede thought about certain political issues such as the Vietnam War and race issues in the United States. In between asking politicians and ordinary denizens of Stockholm about their opinions on politics, she has sex with her drama teacher, classmates, and married men.<br /><br />What kills me about I AM CURIOUS-YELLOW is that 40 years ago, this was considered pornographic. Really, the sex and nudity scenes are few and far between, even then it\\'s not shot like some cheaply made porno. While my countrymen mind find it shocking, in reality sex and nudity are a major staple in Swedish cinema. Even Ingmar Bergman, arguably their answer to good old boy John Ford, had sex scenes in his films.<br /><br />I do commend the filmmakers for the fact that any sex shown in the film is shown for artistic purposes rather than just to shock people and make money to be shown in pornographic theaters in America. I AM CURIOUS-YELLOW is a good film for anyone wanting to study the meat and potatoes (no pun intended) of Swedish cinema. But really, this film doesn\\'t have much of a plot.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a5da122df8a52909"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
