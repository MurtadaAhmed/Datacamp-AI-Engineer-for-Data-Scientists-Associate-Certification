{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-03-29T10:03:58.351996Z",
     "start_time": "2025-03-29T10:03:58.150234Z"
    }
   },
   "source": [
    "from PIL.ImagePalette import negative\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "from transformers import pipeline",
   "id": "d5f342ec76a6a894"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:11:02.517005Z",
     "start_time": "2025-03-29T10:11:01.734270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import (\n",
    "    SummarizationPipeline,\n",
    "    TextClassificationPipeline,\n",
    "    AudioClassificationPipeline,\n",
    "    ImageSegmentationPipeline\n",
    "    )"
   ],
   "id": "814311d857496719",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:15:20.716312Z",
     "start_time": "2025-03-29T10:15:20.443985Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "my_pipeline = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
    ")\n",
    "positive_input = \"Hi, welcome to this course\"\n",
    "print(my_pipeline(positive_input))\n",
    "\n",
    "negative_input = \"Oh no!\"\n",
    "print(my_pipeline(negative_input))"
   ],
   "id": "82fcba0e6fdb13bc",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9996154308319092}]\n",
      "[{'label': 'NEGATIVE', 'score': 0.994263231754303}]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# NLP and tokenization",
   "id": "4d17c1a7a5efb9ad"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:33:12.663333Z",
     "start_time": "2025-03-29T10:33:12.458918Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
    "sample_text = \"HOWDY, hoW aRe yoU?\"\n",
    "normalizer = tokenizer.backend_tokenizer.normalizer.normalize_str(sample_text)\n",
    "normalizer"
   ],
   "id": "14fae73a10927e9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'howdy, how are you?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:39:02.688148Z",
     "start_time": "2025-03-29T10:39:02.208668Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# using GPT2Tokenizer\n",
    "from transformers import GPT2Tokenizer, DistilBertTokenizer\n",
    "sample_text = \"HOWDY, hoW aRe yoU?\"\n",
    "\n",
    "gpt_tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "gpt_tokens = gpt_tokenizer.tokenize(sample_text)\n",
    "print(f\"GPT Tokenizer result {gpt_tokens}\")\n",
    "\n",
    "distil_tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "distil_tokens = distil_tokenizer.tokenize(sample_text)\n",
    "print(f\"Distil Tokenizer result {distil_tokens}\")"
   ],
   "id": "b194839e4322f3e0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT Tokenizer result ['HOW', 'D', 'Y', ',', 'Ġho', 'W', 'Ġa', 'Re', 'Ġyo', 'U', '?']\n",
      "Distil Tokenizer result ['how', '##dy', ',', 'how', 'are', 'you', '?']\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Text classification\n",
    "- Sentiment analysis\n",
    "- Question Natural Language Inference (QNLI)\n",
    "- Topic modeling\n",
    "- Grammatical correctness"
   ],
   "id": "95fca81a4818245"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:50:37.496867Z",
     "start_time": "2025-03-29T10:50:26.638612Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "classifier = pipeline(task=\"text-classification\")\n",
    "text = \"I love it\"\n",
    "classifier(text)"
   ],
   "id": "fb31904a8bb53a86",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision 714eb0f (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998799562454224}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T10:53:52.826701Z",
     "start_time": "2025-03-29T10:53:51.865208Z"
    }
   },
   "cell_type": "code",
   "source": [
    "classifier = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"abdulmatinomotoso/English_Grammar_Checker\"\n",
    ")\n",
    "text = \"i write love cheese book doing\"\n",
    "print(classifier(text)) # [{'label': 'LABEL_0', 'score': 0.9968376159667969}] >>> LABEL_0 means unacceptable\n",
    "\n",
    "text = \"I am studying at the moment.\"\n",
    "print(classifier(text)) # [{'label': 'LABEL_1', 'score': 0.9997439980506897}] >> LABEL_1 means acceptable"
   ],
   "id": "9658be85a3f6ed4b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_0', 'score': 0.9968376159667969}]\n",
      "[{'label': 'LABEL_1', 'score': 0.9997439980506897}]\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:06:28.483492Z",
     "start_time": "2025-03-29T11:06:10.902536Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# QNLI\n",
    "qnli_pipeline = pipeline(\n",
    "    task=\"text-classification\",\n",
    "    model=\"bert-base-uncased\"\n",
    ")\n",
    "question = \"Where is the capital of Bulgaria?\"\n",
    "answer = \"Sofia is the capital of Bulgaria.\"\n",
    "result = qnli_pipeline(f\"{question} {answer}\")\n",
    "print(result)"
   ],
   "id": "e0c2c61b97e83c09",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'LABEL_1', 'score': 0.5798683166503906}]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:10:09.180514Z",
     "start_time": "2025-03-29T11:10:06.203252Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# zero-shot classification\n",
    "classifier = pipeline(\n",
    "    task=\"zero-shot-classification\",\n",
    "    model=\"facebook/bart-large-mnli\"\n",
    ")\n",
    "\n",
    "text = \"There is a war in Africe\"\n",
    "labels = ['politics', 'science', 'technology']\n",
    "\n",
    "classifier(text, labels)"
   ],
   "id": "ec5242b032cd06a5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sequence': 'There is a war in Africe',\n",
       " 'labels': ['politics', 'technology', 'science'],\n",
       " 'scores': [0.6817732453346252, 0.1779291331768036, 0.14029757678508759]}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 29
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Summarization",
   "id": "c62fba04951f4ffc"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-29T11:21:04.382058Z",
     "start_time": "2025-03-29T11:21:01.504329Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import pipeline\n",
    "summarize = pipeline(\n",
    "    task='summarization',\n",
    "    model='sshleifer/distilbart-cnn-12-6',\n",
    "    min_length=5,\n",
    "    max_length=20,\n",
    ")\n",
    "text = \"The transformers library, developed by Hugging Face, is used for natural language processing (NLP) tasks. It provides pre-trained models and tools for various NLP applications such as text classification, sentiment analysis, summarization, translation, and more. The library supports a wide range of transformer-based models like BERT, GPT, and T5, making it easier to implement and fine-tune these models for specific tasks.\"\n",
    "\n",
    "summarize(text)"
   ],
   "id": "bd2171a1860d8486",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'summary_text': ' The transformers library, developed by Hugging Face, is used for natural language processing'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "7698a3bfb6e7d05b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
